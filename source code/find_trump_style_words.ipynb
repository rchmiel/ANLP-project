{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "#This code finds the Trump style words\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "import nltk\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#General word rank\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#from: http://www.anc.org/data/anc-second-release/frequency-data/\n",
    "\n",
    "#create a dictionary with the most frequent generally used words and their respective rank\n",
    "word_rank_file = open(\"..\\\\data\\\\wordranking.txt\")\n",
    "word_rank_text = word_rank_file.read()\n",
    "word_freq_dict = {}\n",
    "for word_rank in word_rank_text.split(\"\\n\"):\n",
    "    word = word_rank.split()[1].lower()\n",
    "    if word in word_freq_dict: #words are counted separately for each POS tag, so we sum them up\n",
    "        word_freq_dict[word] = word_freq_dict[word]+ int(word_rank.split()[3])\n",
    "    else:\n",
    "        word_freq_dict[word] = int(word_rank.split()[3])\n",
    "\n",
    "word_rank_dict={key: rank for rank, key in enumerate(sorted(word_freq_dict, key=word_freq_dict.get, reverse=True), 1)}\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Trump word rank\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#load the cleaned Trump corpus\n",
    "final_trump_file = open(\"..\\\\data\\\\final_trump_corpus.txt\")\n",
    "final_trump_corpus = final_trump_file.read().split(\"\\n\")\n",
    "\n",
    "#final_trump_corpus=load(\"final_trump_corpus.txt\")\n",
    "tokenized_text = [nltk.word_tokenize(sentence) for sentence in final_trump_corpus]\n",
    "\n",
    "#reconnect @ to name -> @barackobama\n",
    "final_text=[]\n",
    "for tokenized_sentence in tokenized_text:\n",
    "    skip =[]\n",
    "    for idx,word in enumerate(tokenized_sentence):\n",
    "        if idx not in skip:\n",
    "            if word==\"@\":\n",
    "                final_text.append(\"@\"+tokenized_sentence[idx+1])\n",
    "                skip.append(idx+1)\n",
    "            else:\n",
    "                final_text.append(word.lower())\n",
    "                \n",
    "freq_dist = nltk.FreqDist(final_text)\n",
    "freq_list = freq_dist.most_common()\n",
    "\n",
    "#create a word rank dict for the Trump corpus\n",
    "trump_word_rank_dict = {}\n",
    "for rank, word in enumerate(freq_list[:500]):\n",
    "    trump_word_rank_dict[word[0]]= rank+1\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Compare the word rankings\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "compare_dict={}\n",
    "not_in_5000 = {} #the words not appearing in the top 5000 at all\n",
    "\n",
    "#irrelevant words (for example 're with different '’` etc.)\n",
    "irrelevant = [\"'re\", \"'m\", \"is\", \"are\", \"was\", \"were\",\"am\", \"has\", \"have\", \"t\", \"do\", \"does\", \"did\", \"don\", \"did\"]\n",
    "for word,rank in trump_word_rank_dict.items():\n",
    "    if word not in '!\"#$%&\\'\\'’()*+,--.../:;?@[\\\\]^_{|}~``“”1023456789' and word not in irrelevant:\n",
    "        if word in word_rank_dict:\n",
    "            if (word_rank_dict[word]-rank)>40:\n",
    "                compare_dict[word] = word_rank_dict[word]-rank\n",
    "        else:\n",
    "            not_in_5000[word] = rank\n",
    "            \n",
    "#list of Trumps style words\n",
    "trump_style_words = [ word for word, score in compare_dict.items()]\n",
    "trump_style_words.extend([ word for word, score in not_in_5000.items()])\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Create the dictionary with Trump style words and occurrences\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#open and load topic corpus\n",
    "trump_file_tagged = open(\"..\\\\data\\\\stanford_tagged_trump_corpus.txt\", encoding = \"utf-8\")\n",
    "trump_corpus_tagged = eval(trump_file_tagged.read())\n",
    "\n",
    "#dictionary to collect info about the Trump style words\n",
    "trump_style_dict = {}\n",
    "\n",
    "for sentence in trump_corpus_tagged:\n",
    "    for idx, (word, tag) in enumerate(sentence):\n",
    "        if word.lower() in trump_style_words: \n",
    "            \n",
    "            #find the tag of the word, before the Trump style word\n",
    "            if idx==0:\n",
    "                prior_tag=\"START\"\n",
    "            else:\n",
    "                prior_tag = sentence[idx-1][1]\n",
    "                \n",
    "            #find the tag of the word after the Trump style word    \n",
    "            try:\n",
    "                next_tag = sentence[idx+1][1]\n",
    "            except IndexError:\n",
    "                next_tag = \"END\"\n",
    "            \n",
    "            #create dictionary with counts of each occurance\n",
    "            if (prior_tag,tag,next_tag) not in trump_style_dict:\n",
    "                trump_style_dict[prior_tag,tag,next_tag]={}\n",
    "            if word.lower() not in trump_style_dict[prior_tag,tag,next_tag]:\n",
    "                trump_style_dict[prior_tag,tag,next_tag][word.lower()]=1\n",
    "            else:\n",
    "                trump_style_dict[prior_tag,tag,next_tag][word.lower()]=trump_style_dict[prior_tag,tag,next_tag][word.lower()]+1\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Find the words that occur frequently in a certain context\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "style_dict={}\n",
    "for entry in trump_style_dict:\n",
    "    style_dict[entry]={}\n",
    "    for word,count in trump_style_dict[entry].items():\n",
    "        if count > 50:\n",
    "            style_dict[entry][word]=count\n",
    "\n",
    "final_style_dict={}\n",
    "for entry in style_dict:\n",
    "    if style_dict[entry]!={}:\n",
    "        final_style_dict[entry]=style_dict[entry]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
