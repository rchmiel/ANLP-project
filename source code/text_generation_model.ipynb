{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "#This generates Trump style sentences\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "import random\n",
    "from ngram import NgramModel #to run this import the nltk model branch is needed: https://github.com/nltk/nltk/tree/model\n",
    "from nltk.probability import MLEProbDist\n",
    "from collections import Counter\n",
    "from numpy.random import choice\n",
    "\n",
    "def do_ngram(model, x_gram):\n",
    "#enter the n-gram model and the number of n (2-4)\n",
    "    sentence =[]\n",
    "    \n",
    "    for x in range(0,x_gram - 2): #generate list to start the generation\n",
    "        sentence.append(\"\")\n",
    "    sentence.append(\"START\") \n",
    "    \n",
    "    #generate new tags until \"END\" is reached\n",
    "    while sentence[-1]!= \"END\":\n",
    "        sentence.append(model.generate_one((sentence[-1*x_gram+1:])))\n",
    "    return(sentence[2:])\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Settings\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#range of top words to pick from, have to be >= 1\n",
    "draw_range_start = 2 #number of the most probable words from which the starting word is picked \n",
    "draw_range = 4 #number of the most probable words from which the words are picked within the sentence \n",
    "draw_range_random = 3 #number of the most probable words from which the word is picked, if it has to choose randomly\n",
    "trump_word_insert_prob = 25 #100-p = %-probability that a Trump word is inserted if there are valid instances\n",
    "number_of_sentences = 100 #number of sentences being generated\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Loading all required files\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#load the tagged Trump corpus\n",
    "trump_corpus_file = open(\"..\\\\data\\\\stanford_tagged_trump_corpus.txt\", encoding= \"utf-8\")\n",
    "trump_corpus_tagged = eval(trump_corpus_file.read())\n",
    "\n",
    "#load the emission probability dictionary\n",
    "emission_dict_file = open(\"..\\\\data\\\\emission_dict.txt\", encoding= \"utf-8\")\n",
    "prob_emission_dict = eval(emission_dict_file.read())\n",
    "\n",
    "#open and load topic corpus\n",
    "topic_file_tagged = open(\"..\\\\data\\\\stanford_tagged_topic_corpus.txt\")\n",
    "topic_text_tagged = eval(topic_file_tagged.read())\n",
    "\n",
    "#open and load style dictionary\n",
    "style_dict_file = open(\"..\\\\data\\\\style_dict.txt\")\n",
    "final_style_dict = eval(style_dict_file.read())\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Generate the sentences\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "tag_corpus = []\n",
    "for sentence in trump_corpus_tagged:\n",
    "    tag_sentence = [tag for word, tag in sentence ]\n",
    "    tag_sentence.append(\"END\") #add end tag of tag sequence\n",
    "    tag_sentence.insert(0, \"START\") # add start tag at the beginng of the tag sequence\n",
    "    tag_corpus.append(tag_sentence)\n",
    "\n",
    "#generate model (option to experiment with different models)\n",
    "model = NgramModel(4, tag_corpus, MLEProbDist)\n",
    "\n",
    "sentence_count=0\n",
    "\n",
    "while sentence_count != number_of_sentences:\n",
    "    try:\n",
    "        #create tag sentence\n",
    "        tag_sentence = do_ngram(model, 4)  \n",
    "\n",
    "        #---------------------------------------------------------------------\n",
    "        #Generate output\n",
    "        #---------------------------------------------------------------------\n",
    "        \n",
    "        #generate first word\n",
    "        output_sentence = []\n",
    "        collector = []\n",
    "        \n",
    "        for sentence in topic_text_tagged:\n",
    "            if sentence[0][1] == tag_sentence[1] and sentence[1][1]==tag_sentence[2]:\n",
    "                collector.append(sentence[0][0])\n",
    "                \n",
    "        list_counted = Counter(collector)\n",
    "        words = [pair[0] for pair in list_counted.most_common()[:draw_range_start]]\n",
    "        counts = [pair[1] for pair in list_counted.most_common()]\n",
    "        counts = [count*(1/sum(counts[:draw_range_start])) for count in counts[:draw_range_start]] #counts[:N] normalize prob for only the N most likely\n",
    "        try:\n",
    "            output_sentence.extend(list(choice(words[:draw_range_start],1, p=counts)))\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        for idx,tag in enumerate(tag_sentence):\n",
    "            if idx <2 or tag == \"END\":\n",
    "                continue\n",
    "            else:\n",
    "                collector = []\n",
    "                for sentence in topic_text_tagged:\n",
    "                    for pair_index, pair in enumerate(sentence):\n",
    "                        if pair_index==0:\n",
    "                            continue\n",
    "                        else:\n",
    "                            if pair == (output_sentence[-1], tag_sentence[idx-1]): #if it is the same word with same tag\n",
    "                                try:\n",
    "                                    if sentence[pair_index+1][1] == tag_sentence[idx]:\n",
    "                                        try:\n",
    "                                            if sentence[pair_index+2][1] == sentence[pair_index+1][1]:\n",
    "                                                collector.append(sentence[pair_index+1][0])\n",
    "                                        except IndexError:\n",
    "                                            continue\n",
    "                                except IndexError:\n",
    "                                    continue\n",
    "\n",
    "                list_counted =Counter(collector)\n",
    "                words = [pair[0] for pair in list_counted.most_common()]\n",
    "                counts = [pair[1] for pair in list_counted.most_common()]\n",
    "                counts = [count*(1/sum(counts[:draw_range])) for count in counts[:draw_range]] #counts[:N] normalize prob for only the N most likely\n",
    "                try:\n",
    "                    output_sentence.extend(list(choice(words[:draw_range],1, p=counts))) #word[:N] only the N most probable words\n",
    "                except ValueError: #if error then pick random word from emission probabilities\n",
    "                    try:\n",
    "                        count += 1\n",
    "                        words = [pair[0] for pair in prob_emission_dict[tag].items()]\n",
    "                        counts = [pair[1] for pair in prob_emission_dict[tag].items()]\n",
    "                        counts = [count*(1/sum(counts[:draw_range_random])) for count in counts[:draw_range_random]] #counts[:N] normalize prob for only the N most likely\n",
    "                        output_sentence.extend(list(choice(words[:draw_range_random],1, p=counts))) #word[:N] only the N most probable words\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "\n",
    "        #---------------------------------------------------------------------\n",
    "        #Check if instances where Trump style words could be inserted exist\n",
    "        #---------------------------------------------------------------------\n",
    "        \n",
    "        def find_sequence(subseq, seq):\n",
    "            #\"brute force approach to search for subsequence in a list and to return the start index of it\"\n",
    "            i, n, m = -1, len(seq), len(subseq)\n",
    "            try:\n",
    "                while True:\n",
    "                    i = seq.index(subseq[0], i + 1, n - m + 1)\n",
    "                    if subseq == seq[i:i + m]:\n",
    "                        return i\n",
    "            except ValueError:\n",
    "                return -1\n",
    "\n",
    "        occurance=[]\n",
    "        for tag_sequence in final_style_dict:\n",
    "            tags=[tag for tag in tag_sequence]\n",
    "            if find_sequence(tags, tag_sentence)!=-1:\n",
    "                occurance.append([find_sequence(tags, tag_sentence),tag_sequence]) #2nd word of the tag sequence \n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Randomly replace selected words in the output sentence with Trump style words\n",
    "        #-----------------------------------------------------------------------------\n",
    "        \n",
    "        if occurance != []:\n",
    "            for instance in occurance:\n",
    "                number=random.randint(0, 100)\n",
    "                if number>trump_word_insert_prob: #probability that the word is exchanged\n",
    "                    if len(final_style_dict[instance[1]])>1: \n",
    "                        #for word,count in final_style_dict[instance[1]].items():\n",
    "                        words=[word for word,count in final_style_dict[instance[1]].items()]\n",
    "                        counts=[count for word,count in final_style_dict[instance[1]].items()]\n",
    "                        counts=[count/sum(counts) for count in counts]     \n",
    "                        output_sentence[instance[0]]=\"\".join(list(choice(words,1, p=counts)))\n",
    "                    else:\n",
    "                        for word,count in final_style_dict[instance[1]].items():\n",
    "                            output_sentence[instance[0]] = word\n",
    "        sentence_count += 1\n",
    "        \n",
    "        print(\" \".join(output_sentence), '\\n')\n",
    "\n",
    "    except IndexError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
